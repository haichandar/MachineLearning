{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepNetworks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "xTCDJCXJgjL8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#RUN NN"
      ]
    },
    {
      "metadata": {
        "id": "Suu0L7jqUwFp",
        "colab_type": "code",
        "outputId": "8a4c128a-f029-404c-fdd0-7677c59aad66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sat Dec  8 22:05:38 2018\n",
        "\n",
        "@author: Chandar_S\n",
        "\"\"\"\n",
        "\n",
        "from cnn import cnn\n",
        "from fnn import fnn\n",
        "from rnn import rnn\n",
        "from nn_utilities_py import nn_utilities\n",
        "import tensorflow as tf\n",
        "from scipy.misc import imread\n",
        "import os\n",
        "import numpy as np\n",
        "import pylab\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "\n",
        "data_path = './'\n",
        "nn_utilities_obj = nn_utilities(data_path)\n",
        "\n",
        "def run_test():\n",
        "    nn_utilities_obj.load_PneumothoraxDataset()\n",
        "#    nn_utilities_obj.load_fashion_data()\n",
        "#    nn_utilities_obj.load_mnist_digit_data()\n",
        "#    nn_utilities_obj.prepare_digits_image_inputs()\n",
        "\n",
        "def run_fnn():\n",
        "    fnn_obj = fnn(data_path)\n",
        "\n",
        "    # Flag makes it run with new simplified code and does not run validation accuracy for quicker response\n",
        "    legacy_run = False\n",
        "\n",
        "    ## GET INPUT  DATA\n",
        "#    input_data = nn_utilities_obj.prepare_digits_image_inputs()\n",
        "    input_data = nn_utilities_obj.load_mnist_digit_data()\n",
        "#    input_data = nn_utilities_obj.load_fashion_data()\n",
        "\n",
        "    ## 2 LAYER FNN INPUTS\n",
        "    hiddenlayer_1_width = 256\n",
        "    hiddenlayer_2_width = 256\n",
        "\n",
        "    ## Override the default learning rate\n",
        "    fnn_obj.learning_rate_var = 0.001\n",
        "\n",
        "    if legacy_run == True:\n",
        "        ## CREATE FNN MODEL\n",
        "        optimizer, cost,  accuracy, fnn_model = fnn_obj.create_model(fnn_obj.x, input_data[\"x_train\"].shape[1], hiddenlayer_1_width, hiddenlayer_2_width, input_data[\"y_train\"].shape[1])\n",
        "    else:\n",
        "        ## CREATE FNN MODEL\n",
        "        optimizer, cost,  accuracy, fnn_model = fnn_obj.create_simplified_model(fnn_obj.x, input_data[\"x_train\"].shape[1], hiddenlayer_1_width, hiddenlayer_2_width, input_data[\"y_train\"].shape[1] )\n",
        "\n",
        "    ## TRAIN THE MODEL AND TEST PREDICTION\n",
        "    run_nn(fnn_obj, input_data, optimizer, cost, accuracy, fnn_model, \"fnn_\"+input_data[\"name\"])\n",
        "\n",
        "\n",
        "def run_cnn():\n",
        "    cnn_obj = cnn(data_path)\n",
        "    \n",
        "    # Flag makes it run with new simplified code and does not run validation accuracy for quicker response\n",
        "    legacy_run = False\n",
        "\n",
        "    ''' WE NEED THIS FOR LOOKING AT HEAT MAP OVER IMAGE'''\n",
        "    single_layer_fnn = True\n",
        "\n",
        "    ## Override the default learning rate\n",
        "    cnn_obj.learning_rate_var = 0.0001\n",
        "    \n",
        "    ## GET INPUT  DATA\n",
        "#    input_data = nn_utilities_obj.prepare_digits_image_inputs()\n",
        "#    input_data = nn_utilities_obj.load_mnist_digit_data()\n",
        "#    input_data = nn_utilities_obj.load_fashion_data()\n",
        "    input_data = nn_utilities_obj.load_PneumothoraxDataset()\n",
        "\n",
        "    ## 2 LAYER FNN INPUTS\n",
        "    hiddenlayer_1_width = 500\n",
        "    hiddenlayer_2_width = 500\n",
        "\n",
        "    ## Assuming it's a SQUARE IMAGE\n",
        "    image_height = int(np.sqrt(input_data[\"x_train\"].shape[1]))\n",
        "    image_width = image_height\n",
        "    \n",
        "    if legacy_run == True:\n",
        "        ## CREATE CNN & DNN MODEL\n",
        "        optimizer, cost, accuracy, cnn_fnn_model = cnn_obj.create_model([image_height, image_width], hiddenlayer_1_width, hiddenlayer_2_width, input_data[\"y_train\"].shape[1], single_layer_fnn)\n",
        "    else:\n",
        "        ## CREATE CNN & DNN MODEL\n",
        "        optimizer, cost, accuracy, cnn_fnn_model = cnn_obj.create_simplified_model([image_height, image_width], hiddenlayer_1_width, hiddenlayer_2_width, input_data[\"y_train\"].shape[1], single_layer_fnn)\n",
        "\n",
        "    ## TRAIN THE MODEL AND TEST PREDICTION\n",
        "    run_nn(cnn_obj, input_data, optimizer, cost, accuracy, cnn_fnn_model, \"cnn_\"+input_data[\"name\"], False)\n",
        "\n",
        "\n",
        "def run_rnn():\n",
        "    rnn_obj = rnn(data_path)\n",
        "\n",
        "    ## GET INPUT  DATA\n",
        "#    input_data = nn_utilities_obj.prepare_digits_image_inputs()\n",
        "    input_data = nn_utilities_obj.load_fashion_data()\n",
        "\n",
        "    ## Override the default learning rate\n",
        "    rnn_obj.learning_rate_var = 0.05\n",
        "\n",
        "    ## Assuming it's a SQUARE IMAGE\n",
        "    image_height = int(np.sqrt(input_data[\"x_train\"].shape[1]))\n",
        "    image_width = image_height\n",
        "\n",
        "    # Network Parameters\n",
        "    num_input = image_height # MNIST data input (img shape: 28*28)\n",
        "    timesteps = image_width # timesteps\n",
        "    num_hidden = 128 # hidden layer num of features\n",
        "    num_classes = 10 # MNIST total classes (0-9 digits)\n",
        "\n",
        "    ## CREATE RNN MODEL\n",
        "    optimizer, cost,  accuracy, rnn_model = rnn_obj.create_model(num_input, timesteps, num_hidden, num_classes)\n",
        "\n",
        "    input_data[\"x_train\"] = np.reshape(input_data[\"x_train\"],[input_data[\"x_train\"].shape[0], timesteps,num_input])\n",
        "    input_data[\"x_validation\"] = np.reshape(input_data[\"x_validation\"],[input_data[\"x_validation\"].shape[0], timesteps,num_input])\n",
        "\n",
        "    ## TRAIN THE MODEL AND TEST PREDICTION\n",
        "    run_nn(rnn_obj, input_data, optimizer, cost, accuracy, rnn_model, \"rnn_\"+input_data[\"name\"])\n",
        "\n",
        "\n",
        "def run_nn(obj, input_data, optimizer, cost, accuracy, model, model_name=None, run_validation_accuracy=True):\n",
        "    # Python optimisation variables\n",
        "    training_epochs = 20\n",
        "    display_step = 100\n",
        "    batch_size = 100\n",
        "    quick_training = False\n",
        "\n",
        "    print (\"Starting session\")\n",
        "    #### TRAIN AND TEST NN\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        # TRAIN\n",
        "        trained_model = obj.train_model(sess, model, training_epochs, display_step, batch_size, optimizer, cost, accuracy, input_data[\"x_train\"], input_data[\"x_train_4D\"], input_data[\"y_train\"], input_data[\"x_validation\"], input_data[\"y_validation\"], quick_training, model_name, run_validation_accuracy)\n",
        "\n",
        "        ## TEST\n",
        "        test = input_data[\"test\"]\n",
        "        if (test is not None):\n",
        "            data_dir = input_data[\"data_dir\"]\n",
        "\n",
        "            img_name = obj.rng.choice(test.filename)\n",
        "            filepath = os.path.join(data_dir, 'Numbers', 'Images', 'test', img_name)\n",
        "            img = imread(filepath, flatten=True)\n",
        "            # convert list to ndarray and PREP AS PER INPUT FORMAT\n",
        "            x_test = np.stack(img)\n",
        "            if len(input_data[\"x_train\"].shape) == 2:\n",
        "                x_test = x_test.reshape(-1, input_data[\"x_train\"].shape[1])\n",
        "            else:\n",
        "                x_test = x_test.reshape(-1, input_data[\"x_train\"].shape[1], input_data[\"x_train\"].shape[2])\n",
        "\n",
        "            ## PREDICT AND VALIDATE\n",
        "            predicted_test = obj.predictvalue(trained_model, x_test)\n",
        "\n",
        "            print(\"Prediction is: \", predicted_test[0])\n",
        "            pylab.imshow(img, cmap='gray')\n",
        "            pylab.axis('off')\n",
        "            pylab.show()\n",
        "    print (\"Ending session\")\n",
        "\n",
        "    ## DO MIT CAM Analysis to print the Heatmap\n",
        "    CAM_analysis = True\n",
        "    if (CAM_analysis == True):\n",
        "        load_saved_model(model_name, obj, input_data)\n",
        "\n",
        "\n",
        "def load_saved_model(model_name, obj, input_data):\n",
        "    with tf.Session() as sess:\n",
        "        saver = tf.train.Saver()\n",
        "        print (\"Restoring Model\")\n",
        "        saver.restore(sess, data_path + \"\"+model_name+\".ckpt\")\n",
        "        \n",
        "        print (\"Starting with CAM Analysis\")\n",
        "        \"\"\"DOING CAM Heatmaps Analysis\"\"\"\n",
        "        \n",
        "        '''extract the features and weights using the function defined directly above '''\n",
        "        (feature_maps, dense_weights) = extract_features_weights(sess, obj) #TODO\n",
        "\n",
        "#        print(\"Feature Maps: \"+str(feature_maps))\n",
        "#        print(\"Dense Weights: \"+str(dense_weights))\n",
        "\n",
        "        '''TODO: compute the CAM for a pneumothorax detection using the function above'''\n",
        "        WHICH_OPTION_INDEX = 1\n",
        "        cam = compute_cam(WHICH_OPTION_INDEX, feature_maps, dense_weights)\n",
        "       \n",
        "        ## Assuming it's a SQUARE IMAGE\n",
        "        image_height = int(np.sqrt(input_data[\"x_train\"].shape[1]))\n",
        "        image_width = image_height\n",
        "\n",
        "        ''' upsample the CAM Tensor to a 28\\times 28 image '''\n",
        "        cam_upsampled =  tf.image.resize_bilinear(cam,  [image_height,image_width])\n",
        "\n",
        "       \n",
        "        inds = []\n",
        "        for check_index in range (1,20):\n",
        "            if np.argmax(input_data[\"y_validation\"][check_index]) == WHICH_OPTION_INDEX:\n",
        "                inds.extend([check_index])\n",
        "        print (inds)\n",
        "#        inds= [79, 31]\n",
        "        input_data[\"y_validation\"] = np.stack(input_data[\"y_validation\"])\n",
        "#        print (type(input_data[\"x_validation\"][1]))\n",
        "#        print (input_data[\"y_validation\"][1])\n",
        "        \n",
        "        for im, cl in zip(input_data[\"x_validation\"][inds], input_data[\"y_validation\"][inds]):\n",
        "            heatmap = sess.run(\n",
        "                cam_upsampled,\n",
        "                feed_dict={\n",
        "                    obj.x: im[np.newaxis,:],\n",
        "                })\n",
        "\n",
        "            vis_cam(im, np.squeeze(heatmap), input_data)\n",
        "        \"\"\"DOING CAM Heatmaps Analysis\"\"\"\n",
        "\n",
        "\n",
        "''' Extract the last Layer weights of CNN and FNN for CAM manipulation'''\n",
        "def extract_features_weights(sess, cnn_obj):\n",
        "    #access feature map activations directly from the model declaration\n",
        "    feature_maps = cnn_obj.cnn_output\n",
        "\n",
        "#    graph = tf.get_default_graph()\n",
        "#    for op in graph.get_operations():\n",
        "#        print(op.name)\n",
        "    \n",
        "    # we have implemented 2 different methods, so handling both scenarios\n",
        "    try:\n",
        "        #access the weights by searching by name\n",
        "        dense_weights = sess.graph.get_tensor_by_name('fnn/FNN_Output_Weight:0')\n",
        "    except:\n",
        "        #access the weights by searching by name\n",
        "        dense_weights = sess.graph.get_tensor_by_name('dense_layer/kernel:0')\n",
        "\n",
        "    return (feature_maps, dense_weights)\n",
        "\n",
        "\n",
        "''' Forms a CAM operation given a class name, feature maps, and weights\n",
        "   \n",
        "    Params: \n",
        "        - class_index: index of the class to measure\n",
        "        - fmap: (1 x h x w x d) tf.Tensor of activations from the final convolutional layer\n",
        "        - weights: (features x #ofoutputclasses) tf.Tensor with the learned weights of the final FC layer\n",
        "    \n",
        "    Returns: \n",
        "        - (16 x 16) tf.Tensor of downscaled CAMs  \n",
        "    '''\n",
        "def compute_cam(class_index, fmap, weights):\n",
        "    w_vec = tf.expand_dims(weights[:, class_index], 1)\n",
        "    _, h, w, c = fmap.shape.as_list()\n",
        "    fmap = tf.squeeze(fmap) # remove batch dim\n",
        "    fmap = tf.reshape(fmap, [h * w, c])\n",
        "    # compute the CAM! Remeber to look at the equation defining CAMs above to do this \n",
        "    CAM = tf.matmul(fmap, w_vec) # TODO\n",
        "    CAM = tf.reshape(CAM, [1, h, w, 1])\n",
        "\n",
        "    return CAM\n",
        "\n",
        "\n",
        "\"\"\" Visualize class activation heatmap, overlaying on image.\"\"\"\n",
        "def vis_cam(image, cam, input_data, save_file=None):\n",
        "#    print (cam)\n",
        "    \n",
        "    if (cam.min() != cam.max()):\n",
        "        cam = (cam - cam.min()) / (cam.max() - cam.min()) # TODO: check\n",
        "    ## Assuming it's a SQUARE IMAGE\n",
        "    image_height = int(np.sqrt(input_data[\"x_train\"].shape[1]))\n",
        "    image_width = image_height\n",
        "\n",
        "    image = image.reshape(image_height, image_width, 1 )\n",
        "    plt.imshow(255-image.squeeze(), cmap=plt.cm.gray)\n",
        "    plt.imshow(1-cam, cmap=plt.cm.jet, alpha=0.5, interpolation='nearest', vmin=0, vmax=1)\n",
        "\n",
        "    if save_file:\n",
        "        plt.savefig(save_file)\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  \n",
        "    code = 'cnn'\n",
        "    if (code == \"cnn\"):\n",
        "        print (\"Running CNN model\")\n",
        "        run_cnn()\n",
        "    elif (code == \"fnn\"):\n",
        "        print (\"Running FNN model\")\n",
        "        run_fnn()\n",
        "    elif (code == \"rnn\"):\n",
        "        print (\"Running RNN model\")\n",
        "        run_rnn()\n",
        "    elif (code == \"test\"):\n",
        "        print (\"Running Test\")\n",
        "        run_test()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4739d5db2c1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\"\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cnn'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "YlqxYJtKXXDz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}